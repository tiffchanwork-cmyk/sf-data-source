import requests
from bs4 import BeautifulSoup
import json
import re
import os

# --- è¨­å®šç›®æ¨™ç¶²å€ ---
URLS = {
    'station': 'https://htm.sf-express.com/hk/tc/dynamic_function/S.F.Network/SF_store_address/',
    'locker': 'https://htm.sf-express.com/hk/tc/dynamic_function/S.F.Network/SF_Locker/'
}

# --- è¨­å®šè¼¸å‡ºæª”å ---
FILES = {
    'station': 'sf-stores.json',
    'locker': 'sf-lockers.json'
}

# åœ°å€éæ¿¾é»‘åå–® (é‡åˆ°é€™äº›é—œéµå­—å°±ä¸æ˜¯æœ‰æ•ˆåœ°å€)
DISTRICT_BLACKLIST = ["åœ°å€", "ç¶²é»", "å¿«é", "æœå‹™", "ç†±ç·š", "åœ°å€", "é›»è©±", "æ™‚é–“"]

def clean_text(text):
    """æ¸…ç†æ–‡å­—ï¼šç§»é™¤æ›è¡Œã€å¤šé¤˜ç©ºç™½ã€å…¨å½¢ç©ºæ ¼"""
    if not text: return ""
    text = text.replace('\u3000', ' ').replace('\xa0', ' ')
    return re.sub(r'\s+', ' ', text).strip()

def fetch_and_parse(url, type_key):
    print(f"[{type_key}] æ­£åœ¨é€£ç·šé †è±å®˜ç¶²æŠ“å–ä¸­...")
    
    try:
        # å½è£æˆç€è¦½å™¨ï¼Œé¿å…è¢«æ“‹
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        }
        response = requests.get(url, headers=headers, timeout=30)
        response.encoding = 'utf-8'

        if response.status_code != 200:
            print(f"âŒ [{type_key}] é€£ç·šå¤±æ•— (Code: {response.status_code})")
            return []

        soup = BeautifulSoup(response.text, 'html.parser')
        results = []
        seen_codes = set() 
        current_district = "å…¶ä»–åœ°å€" 

        # æŠ“å–æ‰€æœ‰è¡¨æ ¼åˆ—
        rows = soup.find_all('tr')
        print(f"[{type_key}] ç¶²é å…±æ‰¾åˆ° {len(rows)} è¡Œï¼Œé–‹å§‹æ™ºæ…§éæ¿¾...")

        for row in rows:
            cols = row.find_all('td')
            
            # å¦‚æœæ¬„ä½å¤ªå°‘ï¼Œé€šå¸¸ä¸æ˜¯è³‡æ–™è¡Œï¼Œè·³é
            if len(cols) < 2:
                continue

            # æå–æ–‡å­—
            raw_district = clean_text(cols[0].get_text())
            code = clean_text(cols[1].get_text())
            
            # å˜—è©¦æå–åœ°å€ (åœ°å€æœ‰æ™‚åœ¨ç¬¬3æ¬„ï¼Œæœ‰æ™‚åœ¨æœ€å¾Œä¸€æ¬„)
            address = ""
            if len(cols) >= 3:
                address = clean_text(cols[2].get_text())
            else:
                address = clean_text(cols[-1].get_text()) # å‚™æ¡ˆ

            # --- [éæ¿¾é‚è¼¯ 1]ï¼šè™•ç†åœ°å€ (District) ---
            # å¦‚æœç¬¬ä¸€æ¬„æœ‰å­—ï¼Œä¸”ä¸æ˜¯ã€Œåœ°å€ã€ã€ã€Œå¿«éæœå‹™ã€ç­‰åƒåœ¾å­—ï¼Œå°±æ›´æ–°ç•¶å‰åœ°å€
            if raw_district and 2 <= len(raw_district) <= 8: # æ”¾å¯¬åœ°å€é•·åº¦é™åˆ¶
                # ã€ä¿®æ­£é»ã€‘é€™è£¡åŸæœ¬å¯«éŒ¯æˆ raw_distï¼Œå·²æ›´æ­£ç‚º raw_district
                if not any(word in raw_district for word in DISTRICT_BLACKLIST):
                    # æ’é™¤ç´”æ•¸å­—æˆ–è‹±æ–‡çš„"åœ°å€" (é€šå¸¸æ˜¯èª¤åˆ¤)
                    if not re.match(r'^[A-Z0-9]+$', raw_district):
                        current_district = raw_district
            
            # --- [éæ¿¾é‚è¼¯ 2]ï¼šåš´æ ¼æª¢æŸ¥ä»£ç¢¼ (Code) ---
            # é †è±ä»£ç¢¼æ ¼å¼é€šå¸¸æ˜¯è‹±æ•¸æ··åˆ (å¦‚ 852TAL, 852M)
            # æ­£è¦è¡¨é”å¼ï¼šåªå…è¨± A-Z, a-z, 0-9
            # é•·åº¦æ”¹ç‚º {1,15}ï¼Œå…è¨±åƒ 852M é€™ç¨®çŸ­ä»£ç¢¼
            code_match = re.search(r'(H?852[A-Z0-9]{1,10})', row.get_text()) 
            
            if code_match:
                code = code_match.group(1)
            elif not re.match(r'^[A-Za-z0-9]{1,15}$', code):
                continue # å¦‚æœæ—¢æ²’æœ‰æ­£å‰‡åŒ¹é…åˆ°ï¼ŒåŸå§‹æ¬„ä½ä¹Ÿä¸ç¬¦åˆæ ¼å¼ï¼Œå°±è·³é

            # --- [éæ¿¾é‚è¼¯ 3]ï¼šå°æ®ºæ¾³é–€è³‡æ–™ ---
            # æ¾³é–€ä»£ç¢¼ç‰¹å¾µï¼šä»¥ 853 æˆ– H853 é–‹é ­
            if code.startswith('853') or code.startswith('H853'):
                continue
            
            # åœ°å€éæ¿¾
            if "æ¾³é–€" in current_district or "æ°¹ä»”" in current_district or "é»‘æ²™ç’°" in current_district:
                continue
                
            # åœ°å€éæ¿¾ (é›™é‡ä¿éšª)
            if "æ¾³é–€" in address:
                continue
            
            # é¿å…é‡è¤‡æŠ“å–
            if code in seen_codes:
                continue

            # --- é€šéæ‰€æœ‰æª¢æŸ¥ï¼ŒåŠ å…¥çµæœ ---
            item = {
                "code": code,
                "address": address,
                "district": current_district
            }
            results.append(item)
            seen_codes.add(code)

        print(f"âœ… [{type_key}] éæ¿¾å®Œç•¢ï¼ŒæˆåŠŸæå–æœ‰æ•ˆè³‡æ–™: {len(results)} ç­†")
        return results

    except Exception as e:
        print(f"âŒ [{type_key}] ç™¼ç”ŸéŒ¯èª¤: {e}")
        return []

def main():
    print("=== é–‹å§‹åŸ·è¡Œé †è±åœ°å€æŠ“å–è…³æœ¬ (V2 ä¿®æ­£è®Šæ•¸åç¨±) ===")
    
    # 1. æŠ“å–é †è±ç«™
    stations = fetch_and_parse(URLS['station'], 'station')
    if stations:
        with open(FILES['station'], 'w', encoding='utf-8') as f:
            json.dump(stations, f, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ å·²å„²å­˜: {FILES['station']}")

    # 2. æŠ“å–æ™ºèƒ½æ«ƒ
    lockers = fetch_and_parse(URLS['locker'], 'locker')
    if lockers:
        with open(FILES['locker'], 'w', encoding='utf-8') as f:
            json.dump(lockers, f, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ å·²å„²å­˜: {FILES['locker']}")

    print("\n=== å®Œæˆï¼æª”æ¡ˆå·²ç”Ÿæˆ ===")
    print("1. sf-stores.json (åŒ…å«çŸ­ä»£ç¢¼ç«™é»å¦‚ 852M)")
    print("2. sf-lockers.json")
    print("è«‹å°‡é€™å…©å€‹æª”æ¡ˆä¸Šå‚³è¦†è“‹åˆ° WordPress å¤–æ›è³‡æ–™å¤¾ï¼Œä¸¦åŒæ­¥åˆ° GitHubã€‚")

if __name__ == "__main__":
    main()