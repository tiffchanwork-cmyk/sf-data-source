import requests
from bs4 import BeautifulSoup
import json
import re
import os

# --- è¨­å®šç›®æ¨™ç¶²å€ ---
URLS = {
    'station': 'https://htm.sf-express.com/hk/tc/dynamic_function/S.F.Network/SF_store_address/',
    'locker': 'https://htm.sf-express.com/hk/tc/dynamic_function/S.F.Network/SF_Locker/'
}

# --- è¨­å®šè¼¸å‡ºæª”å ---
FILES = {
    'station': 'sf-stores.json',
    'locker': 'sf-lockers.json'
}

# åœ°å€éæ¿¾é»‘åå–®
DISTRICT_BLACKLIST = ["åœ°å€", "ç¶²é»", "å¿«é", "æœå‹™", "ç†±ç·š", "åœ°å€", "é›»è©±", "æ™‚é–“"]

def clean_text(text):
    """æ¸…ç†æ–‡å­—ï¼šç§»é™¤æ›è¡Œã€å¤šé¤˜ç©ºç™½ã€å…¨å½¢ç©ºæ ¼"""
    if not text: return ""
    text = text.replace('\u3000', ' ').replace('\xa0', ' ')
    # ç§»é™¤åœ°å€ä¸­å¯èƒ½å‡ºç¾çš„ ^ ç¬¦è™Ÿ (é †è±ç¶²é ç‰¹ç”¢)
    text = text.replace('^', '')
    return re.sub(r'\s+', ' ', text).strip()

def fetch_and_parse(url, type_key):
    print(f"[{type_key}] æ­£åœ¨é€£ç·šé †è±å®˜ç¶²æŠ“å–ä¸­...")
    
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        }
        response = requests.get(url, headers=headers, timeout=30)
        response.encoding = 'utf-8'

        if response.status_code != 200:
            print(f"âŒ [{type_key}] é€£ç·šå¤±æ•— (Code: {response.status_code})")
            return []

        soup = BeautifulSoup(response.text, 'html.parser')
        results = []
        seen_codes = set() 
        current_district = "å…¶ä»–åœ°å€" 

        rows = soup.find_all('tr')
        print(f"[{type_key}] ç¶²é å…±æ‰¾åˆ° {len(rows)} è¡Œï¼Œé–‹å§‹åˆ†æ...")

        for row in rows:
            cols = row.find_all('td')
            
            # é †è±è¡¨æ ¼æ¨™æº–çµæ§‹ï¼š[0]åœ°å€ [1]é»ç¢¼ [2]åœ°å€ [3]æ™‚é–“...
            # å¦‚æœæ¬„ä½å°‘æ–¼ 3 å€‹ï¼Œè‚¯å®šä¸æ˜¯æœ‰æ•ˆè³‡æ–™
            if len(cols) < 3:
                continue

            # --- 1. æå–åŸå§‹è³‡æ–™ (å¼·åˆ¶é–å®šæ¬„ä½) ---
            raw_district_text = clean_text(cols[0].get_text())
            code_text = clean_text(cols[1].get_text())
            address_text = clean_text(cols[2].get_text()) # å¼·åˆ¶è®€å–ç¬¬3æ¬„ï¼Œçµ•ä¸è®€æœ€å¾Œä¸€æ¬„

            # --- 2. è™•ç†åœ°å€ (District) ---
            # å¦‚æœç¬¬ä¸€æ¬„æœ‰å­—ï¼Œæ›´æ–°ç•¶å‰åœ°å€
            if raw_district_text:
                # æ’é™¤æ¨™é¡Œåˆ— (ä¾‹å¦‚å«æœ‰ "åœ°å€" å…©å­—çš„)
                if not any(word in raw_district_text for word in DISTRICT_BLACKLIST):
                    # æ’é™¤ç´”ä»£ç¢¼èª¤æ¤ç‚ºåœ°å€çš„æƒ…æ³
                    if not re.match(r'^[A-Z0-9]+$', raw_district_text):
                        current_district = raw_district_text

            # --- 3. è™•ç†ä»£ç¢¼ (Code) ---
            # ä½¿ç”¨æ­£å‰‡è¡¨é”å¼æå–ä¹¾æ·¨çš„ä»£ç¢¼ (ä¿ç•™ 852M é€™ç¨®çŸ­ä»£ç¢¼)
            code_match = re.search(r'(H?852[A-Z0-9]{1,10})', code_text)
            
            if not code_match:
                continue # æ‰¾ä¸åˆ°æœ‰æ•ˆä»£ç¢¼å°±è·³é

            code = code_match.group(1)

            # --- 4. éæ¿¾é‚è¼¯ ---
            # A. æ’é™¤æ¾³é–€ (853é–‹é ­)
            if code.startswith(('853', 'H853')):
                continue
            
            # B. æ’é™¤é‡è¤‡
            if code in seen_codes:
                continue

            # C. æ’é™¤åœ°å€æˆ–åœ°å€ä¸­çš„æ¾³é–€é—œéµå­—
            if "æ¾³é–€" in current_district or "æ°¹ä»”" in current_district or "æ¾³é–€" in address_text:
                continue

            # --- 5. åœ°å€æœ€çµ‚æ¸…æ´— ---
            # æœ‰äº›åœ°å€æ¬„ä½æœƒåŒ…å«ä»£ç¢¼æœ¬èº« (ä¾‹å¦‚ "852M ä¸Šç’°...")ï¼ŒæŠŠå®ƒå»æ‰
            if address_text.startswith(code):
                address_text = address_text.replace(code, '', 1).strip()
            
            # å»é™¤é–‹é ­çš„æ¨™é»ç¬¦è™Ÿ
            address_text = address_text.lstrip('-,. ')

            results.append({
                "code": code,
                "address": address_text,
                "district": current_district
            })
            seen_codes.add(code)

        print(f"âœ… [{type_key}] æˆåŠŸæå–: {len(results)} ç­† (å·²æ’é™¤æ™‚é–“èª¤åˆ¤)")
        return results

    except Exception as e:
        print(f"âŒ [{type_key}] ç™¼ç”ŸéŒ¯èª¤: {e}")
        return []

def main():
    print("=== é–‹å§‹åŸ·è¡Œé †è±åœ°å€æŠ“å–è…³æœ¬ (V3 å¼·åˆ¶é–å®šåœ°å€æ¬„ä½) ===")
    
    # 1. æŠ“å–é †è±ç«™
    stations = fetch_and_parse(URLS['station'], 'station')
    if stations:
        with open(FILES['station'], 'w', encoding='utf-8') as f:
            json.dump(stations, f, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ å·²å„²å­˜: {FILES['station']}")

    # 2. æŠ“å–æ™ºèƒ½æ«ƒ
    lockers = fetch_and_parse(URLS['locker'], 'locker')
    if lockers:
        with open(FILES['locker'], 'w', encoding='utf-8') as f:
            json.dump(lockers, f, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ å·²å„²å­˜: {FILES['locker']}")

    print("\n=== å®Œæˆï¼æª”æ¡ˆå·²ç”Ÿæˆ ===")
    print("è«‹åŸ·è¡Œä»¥ä¸‹æŒ‡ä»¤å°‡ä¿®æ­£å¾Œçš„è³‡æ–™æ¨é€åˆ° GitHubï¼š")
    print("1. python sf_scraper.py")
    print("2. git add .")
    print("3. git commit -m \"Fix address showing time issue\"")
    print("4. git push")

if __name__ == "__main__":
    main()